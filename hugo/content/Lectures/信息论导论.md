---
course: ''
date: 2025-06-18 18:26:21
draft: false
publish: true
tags: null
title: <% tp.file.title %>
---

# 信息学导论
## 香农定理与理解
1. 香农第一定理（可变长无失真信源编码定理)
	1. 1. **一段信息的信息量是固定的，这称为这段信息的信息熵（H）**
	2. **无论怎么压缩，信息熵是无失真信源编码的极限值**（类似光速）
		1. huffman编码原理
	3. **若编码的平均码长小于信息熵值，必然发生差错（也就是有损）**
2. 香农第二定理（有噪信道编码定理）
	1. **傅里叶公式能把时间信息变成频谱信息**
	2. **_数学公式的信噪比_**
3. 香农第三定理（保失真度准则下的有失真信源编码定理）
	1. 总能找到一种有效的编码方法，让信息的传输率接近信道容量时而不出错，出错指的是无法传输出去，接受一定的失真

第一定律定死了信息无损压缩的极限值，第二定律定死了最大容量，而第三定理，讲得是如何在这些限制下，让通信不出错

![[Pasted image 20250303202615.png]]

https://www.zhihu.com/question/447161080/answer/1759158425


## 定义信息量的本质
使用二进制的原因
- **工程实用性**：二进制是数字通信与计算机的基础（0/1、开关、电压高低）。
- **数学简洁性**：使用 log₂ 时，熵值 H(X)H(X) 直接表示“平均所需二进制位数”，例如：
- **与编码效率关联**
信息量度量的是一个具体事件发生了所带来的信息，而熵则是在结果出来之前对可能产生的信息量的期望——考虑该随机变量的所有可能取值，即所有可能发生事件所带来的信息量的 期望。说白了，信息熵就是信息量的数学期望

## 如何证明信息是可以量化的？
- **公理1：连续性**  
    熵 H(p1,p2,…,pn)H(p1​,p2​,…,pn​) 是概率分布 {pi}{pi​} 的连续函数，即概率微小变化不会导致熵剧烈波动。
- **公理2：等概率极值性**  
    当所有事件等概率（即 pi=1npi​=n1​）时，熵随 nn 单调增加。例如：
    - 抛硬币（n=2）熵为1比特，骰子（n=6）熵为 log⁡26≈2.58log2​6≈2.58 比特。
- **公理3：可加性**  
    若一个随机事件可分解为多个独立步骤，总熵等于各步骤熵之和。
**结论**：唯一满足上述公理的函数形式为 H(X)=−k∑pilog⁡piH(X)=−k∑pi​logpi​，其中 kk 为常数（通常取1，单位由对数底决定）。

## Boolean Algebra
用于进行逻辑运算的数学结构，离散数学中产生，与二进制紧密关联，使用公式结构表示逻辑
基于集合论的基础
属于高等代数内容，数理逻辑导论

# 文学社会类
## post-modern
对现代主义的怀疑和背离，相信去中心化，对传统的观念思考进行解构和挑战，强调多样性的同时分析语言和符号的建构
## modern
对传统的突破和创新，追求一种普遍的真理和进步，相信可以通过科学技术、理性思维解决社会问题，相信社会史不断发展进步的，相信存在普遍真理的乐观态度，人类中心地位。